{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/meryreddoor/yogagame_/blob/primeraRama/Cropping_images.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "XXLpzGPxAIc2",
    "outputId": "5203fe4b-b333-48e6-b6ef-26d2d51225a9"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-31a890acd61a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatches\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2_imshow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#reading the image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/Vriksasana.jpg\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIMREAD_UNCHANGED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from google.colab.patches import cv2_imshow\n",
    "\n",
    "#reading the image \n",
    "image = cv2.imread(\"/content/Vriksasana.jpg\", cv2.IMREAD_UNCHANGED)\n",
    "edged = cv2.Canny(image, 10, 250)\n",
    "cv2_imshow(image)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "\n",
    "#applying closing function \n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (7, 7))\n",
    "closed = cv2.morphologyEx(edged, cv2.MORPH_CLOSE, kernel)\n",
    "cv2_imshow(closed)\n",
    "cv2.waitKey(0)\n",
    " \n",
    "#finding_contours \n",
    "(cnts, _) = cv2.findContours(closed.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    " \n",
    "for c in cnts:\n",
    "\tperi = cv2.arcLength(c, True)\n",
    "\tapprox = cv2.approxPolyDP(c, 0.02 * peri, True)\n",
    "\tcv2.drawContours(image, [approx], -1, (0, 255, 0), 2)\n",
    "cv2_imshow(image)\n",
    "cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "colab_type": "code",
    "id": "AnEWH9XHGDfH",
    "outputId": "9135d57d-2b21-4750-ed5f-d186f4de4379"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# load image\n",
    "img = cv2.imread('./real_pics/bakasana.jpg') \n",
    "rsz_img = cv2.resize(img, None, fx=0.25, fy=0.25) # resize since image is huge\n",
    "gray = cv2.cvtColor(rsz_img, cv2.COLOR_BGR2GRAY) # convert to grayscale\n",
    "\n",
    "# threshold to get just the signature\n",
    "retval, thresh_gray = cv2.threshold(gray, thresh=100, maxval=255, type=cv2.THRESH_BINARY)\n",
    "\n",
    "# find where the signature is and make a cropped region\n",
    "points = np.argwhere(thresh_gray==0) # find where the black pixels are\n",
    "points = np.fliplr(points) # store them in x,y coordinates instead of row,col indices\n",
    "x, y, w, h = cv2.boundingRect(points) # create a rectangle around those points\n",
    "x, y, w, h = x-10, y-10, w+20, h+20 # make the box a little bigger\n",
    "crop = gray[y:y+h, x:x+w] # create a cropped region of the gray image\n",
    "\n",
    "# get the thresholded crop\n",
    "retval, thresh_crop = cv2.threshold(crop, thresh=200, maxval=255, type=cv2.THRESH_BINARY)\n",
    "\n",
    "# display\n",
    "cv2.imshow('j.jpg',thresh_crop) \n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1aK6o3I7KwpE"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "authorship_tag": "ABX9TyPdfn6d/SHe4gXIc9sAbKwt",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Cropping images.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
