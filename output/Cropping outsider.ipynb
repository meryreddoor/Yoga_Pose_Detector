{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cropping outsider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemError",
     "evalue": "<class 'cv2.CascadeClassifier'> returned a result with an error set",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.2.0) /Users/travis/build/skvark/opencv-python/opencv/modules/objdetect/src/cascadedetect.cpp:570: error: (-2:Unspecified error) in function 'bool cv::HaarEvaluator::Feature::read(const cv::FileNode &, const cv::Size &)'\n> Invalid HAAR feature (expected: 'rw.r.y + rw.r.height <= H'), where\n>     'rw.r.y + rw.r.height' is 26\n> must be less than or equal to\n>     'H' is 14\n",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-383d5e46e87a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbody_cascade\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCascadeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'haarcascade_fullbody.xml'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mSystemError\u001b[0m: <class 'cv2.CascadeClassifier'> returned a result with an error set"
     ]
    }
   ],
   "source": [
    "body_cascade = cv2.CascadeClassifier('haarcascade_fullbody.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img=cv2.imread('Vriksasana.jpeg', cv2.IMREAD_GRAYSCALE) # get the array of the original pic\n",
    "print(input_img)\n",
    "faces = body_cascade.detectMultiScale(input_img, \n",
    "                                      scaleFactor=1.1,\n",
    "                                      minNeighbors=5)\n",
    "input_img.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y,w,h = faces[0]\n",
    "img_data= input_img[y:y+h,x:x+w]\n",
    "img_data=cv2.resize(img_data,(48,48))\n",
    "    \n",
    "img_data = np.stack(img_data)\n",
    "img_data = img_data / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2 as cv\n",
    "from pathlib import Path\n",
    "from send2trash import send2trash\n",
    "from google_images_download import google_images_download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the graph.\n",
    "with tf.gfile.GFile('./ssdlite_mobilenet_v2_coco_2018_05_09/frozen_inference_graph.pb', 'rb') as f:\n",
    "    graph_def = tf.GraphDef()\n",
    "    graph_def.ParseFromString(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_persons_and_save_crops(asana, graph_def, folder):\n",
    "    with tf.Session() as sess:\n",
    "        # Restore session\n",
    "        sess.graph.as_default()\n",
    "        tf.import_graph_def(graph_def, name='ejemplo acostado')\n",
    "\n",
    "        files = list(Path(folder).glob('*.jpg'))\n",
    "        files.extend(list(Path(folder).glob('*.png')))\n",
    "\n",
    "        for fid,fname in enumerate(files): \n",
    "            # Read and preprocess an image.\n",
    "            img = cv.imread(str(fname))\n",
    "            if(img is not None):\n",
    "                rows = img.shape[0]\n",
    "                cols = img.shape[1]\n",
    "                inp = cv.resize(img, (300, 300))\n",
    "                inp = inp[:, :, [2, 1, 0]]  # BGR2RGB\n",
    "\n",
    "                # Run the model\n",
    "                out = sess.run([sess.graph.get_tensor_by_name('num_detections:0'),\n",
    "                                sess.graph.get_tensor_by_name('detection_scores:0'),\n",
    "                                sess.graph.get_tensor_by_name('detection_boxes:0'),\n",
    "                                sess.graph.get_tensor_by_name('detection_classes:0')],\n",
    "                               feed_dict={'image_tensor:0': inp.reshape(1, inp.shape[0], inp.shape[1], 3)})\n",
    "\n",
    "                # Visualize detected bounding boxes.\n",
    "                num_detections = int(out[0][0])\n",
    "                #print(fname, num_detections)\n",
    "                for i in range(num_detections):\n",
    "                    classId = int(out[3][0][i])\n",
    "                    if(classId==1):\n",
    "                        score = float(out[1][0][i])\n",
    "                        bbox = [float(v) for v in out[2][0][i]]\n",
    "                        if score > 0.3:\n",
    "                            x = int(bbox[1] * cols)\n",
    "                            y = int(bbox[0] * rows)\n",
    "                            right = int(bbox[3] * cols)\n",
    "                            bottom = int(bbox[2] * rows)\n",
    "                            cv.imwrite(folder+str(fid)+'-'+str(i)+'.png', img[y:bottom, x:right])\n",
    "\n",
    "            try:\n",
    "                send2trash(str(fname))\n",
    "            except: pass    \n",
    "        print('cleaning '+asana+' done.')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "#reading the image \n",
    "image = cv2.imread(\"Vriksasana.jpg\")\n",
    "edged = cv2.Canny(image, 10, 250)\n",
    "cv2.imshow(\"Edges\", edged)\n",
    "cv2.waitKey(0)\n",
    " \n",
    "#applying closing function \n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (7, 7))\n",
    "closed = cv2.morphologyEx(edged, cv2.MORPH_CLOSE, kernel)\n",
    "cv2.imshow(\"Closed\", closed)\n",
    "cv2.waitKey(0)\n",
    " \n",
    "#finding_contours \n",
    "(cnts, _) = cv2.findContours(closed.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    " \n",
    "for c in cnts:\n",
    "    peri = cv2.arcLength(c, True)\n",
    "    approx = cv2.approxPolyDP(c, 0.02 * peri, True)\n",
    "    cv2.drawContours(image, [approx], -1, (0, 255, 0), 2)\n",
    "cv2.imshow(\"Output\", image)\n",
    "cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
